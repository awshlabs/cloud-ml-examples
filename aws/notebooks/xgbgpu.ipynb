{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/rapids_sagemaker.png' width=\"600\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> Hyper-Parameter Optimization with RAPIDS + SageMaker </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameter Optimization (HPO) imporves model quality by searching the space of possible 'architecture parameters,' parameters not usually trained during the learning process. \n",
    "\n",
    "This search can significantly boost model quality relative to default parameters and non-expert tuning; however, the search over architectures can take a very long time on a non-accelerated platform.\n",
    "\n",
    "In this notebook, we containerize a RAPIDS workflow and run Bring-Yor-Own-Container SageMaker HPO to show how we can overcome the computational complexity of model search. We accelerate HPO in two key ways: 1. by scaling within a node (e.g., multi-GPU where each GPU brings a magnitude higher core count relative to CPUs), and 2. by scaling across nodes and running parallel trials on cloud instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU + cloud HPO is reduced from a multi-day searche to just a few hours.\n",
    "For example with 10 years of airline data, we found \n",
    "XX overal speedup and XX cost savings\n",
    "~3X cost savings between GPUs and CPUs [ ml.p3.8xlarge vs ml.m5.24xlarge ]. Further cost reduction (up to ~70%) were easily unlocked using spot instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all these powerful tools at our disposal, every data scientist should feel empowered to uplevel their model before serving it to the world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/three_steps_to_hpo.png' width=2000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> Key Choices: </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Dataset Size and S3 Bucket ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We target a large real-world structured dataset or flight logs for US airlines and train a model to predict flight delays ( published monthly since 1987 by the Bureau of Transportation [dataset link](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&DB_URL=)). \n",
    "\n",
    "We host 3 increasingly larger versions of this dataset as directoreis in a public bucket, and offer `1_year` (2019, 7.2M flights), `3_year` (2016-2019, 18M flights) or `10_year` (2009-2019, 125M flights) configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bucket = 'rapidslabdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = '3_year'   \n",
    "assert( dataset_directory in [ '1_year', '3_year', '10_year'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_URI = f's3://{dataset_bucket}/{dataset_directory}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Algorithm ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a ML/algorithm perspective, we offer `XGBoost` and `RandomForest` decision tree models which do quite well on this structured dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_choice = 'XGBoost'\n",
    "assert ( algorithm_choice in [ 'XGBoost', 'RandomForest' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also optionally increase robustness via reshuffles of the train-test split (i.e., cross-validation folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 1  \n",
    "assert ( cv_folds >= 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Code ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we enable the option of running the pipeline in single or multi CPU/GPU within each node. The possible options are `singleCPU`, `singleGPU`, `multiCPU`, and `multiGPU`.\n",
    "The singleCPU option is code written with pandas and sklearn, singleGPU runs RAPIDS cudf and cuml (i.e., GPU equivalents to pandas and sklearn). In both multiCPU and multiGPU we add dask to parallelize the workflows and allow it to run on a cluster of CPUs/GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_choice = 'multiGPU' \n",
    "assert ( code_choice in [ 'singleCPU', 'singleGPU', 'multiCPU', 'multiGPU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Compute Instance ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataset size and compute choice we will try to recommend an instance choice, you are of course welcome to select alternate configurations. In the case of the CPU we choose a large memory instance (ml.r5) since the during training we can get upwards of 200GB of memory utilization when using the 10 year dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = recommend_instance_type ( code_choice, dataset_directory  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_spot_instances_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration_of_experiment_seconds = 60*60*24 # 24 hrs \n",
    "assert ( max_duration_of_experiment_seconds > 60*60*2 ) # 2 hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ HPO ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important choices when running HPO is to choose the bounds of the hyper-parameter search process. Below we've set the ranges of the hyper-parameters to allow for significant variation in all of the different dimensions though you are welcome to try different variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_variable_name = 'num_boost_round' if ('XGBoost' in algorithm_choice) else 'n_estimators'\n",
    "from sagemaker.parameter import ContinuousParameter, IntegerParameter\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth'           : IntegerParameter        ( 5, 15 ),\n",
    "    n_trees_variable_name : IntegerParameter        ( 100, 500 ),\n",
    "    'max_features'        : ContinuousParameter     ( 0.1, 1.0 ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to decide the search strategy, how may total experiments/jobs to run, and how many jobs can run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_strategy = 'Bayesian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_parallel_jobs = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_jobs = 4  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> Validate: </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to capture our configuration choices into unique job names when we submit our Estimator for testing and when we run HPO. These job names will allows us to do experiment tracking, and also enable the correct code to run inside the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_job_name_from_config( dataset_directory, code_choice, algorithm_choice, cv_folds, instance_type );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_choices( s3_data_URI, code_choice, algorithm_choice, cv_folds,\n",
    "                   instance_type, use_spot_instances_flag, search_strategy, \n",
    "                   max_jobs, max_parallel_jobs, max_duration_of_experiment_seconds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> 1. Build ML Pipeline </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/airline_dataset.png' width='1250px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 1.1 - Dataset </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we'll utilize the Airline dataset (Carrier On-Time Performance 1987-2020, available from the [Bureau of Transportation Statistics](https://transtats.bts.gov/Tables.asp?DB_ID=120&DB_Name=Airline%20On-Time%20Performance%20Data&DB_Short_Name=On-Time#)). \n",
    "\n",
    "For each flight the features in the data include information about time, the airline, source and destination airports, distance, and departure delay. Using these features we'll be trying to build a classifier model to predict whether a flight is going to be more than 15 minutes late on arrival as it prepares to depart.\n",
    "\n",
    "We have a cleaned version of our dataset on a public S3 bucket, which we specify here and will subsequently use as an input to our HPO Estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 1.2 - Python DS Workflow [ ETL, Train, Eval ] </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../code/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../code/rapids_cloud_ml.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to point the code at your own data, just modify the top few lines of train.py and be sure that the `dataset_columns` (columns/features of you dataset) and `target_variable` (the label column which will be the classification target) match your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> 2. Define Estimator </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a RAPIDS enabled SageMaker HPO we first need to build an Estimator. \n",
    "\n",
    "An Estimator is a docker container image that captures all the software needed to run an HPO experiment.\n",
    "\n",
    "The container is augmented with special **entrypoint code** that will be triggered at runtime by each worker. \n",
    "\n",
    "The entrypoint code enables us to write custom models and hook them up to data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/estimator.png'>\n",
    "\n",
    "If you want to dig into the custom code, check out the `train.py` script as well as its supporting library `rapids_cloud_ml.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with SageMaker HPO, the entrypoint logic should parse hyper-parameters (supplied by AWS SageMaker), load and split data, build and train a model, score/evaluate the trained model, and emit an output representing the final score for the given hyper-parameter setting.\n",
    "\n",
    "We've already built sample entrypoint code leveraging the cuml.RandomForest classifier model. If you would like to make changes by adding your custom model logic feel free to modify the **train.py** file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 2.1 - Containerize and Push to ECR </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets turn to building our container so that it can integrate with the AWS SageMaker HPO API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get things rolling lets make sure we can query our AWS SageMaker execution role and session as well as our account ID and AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_execution_role = sagemaker.get_execution_role()\n",
    "sm_session = sagemaker.Session()\n",
    "\n",
    "account=!(aws sts get-caller-identity --query Account --output text)\n",
    "region=!(aws configure get region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account, region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our container takes the latest RAPIDS [ nightly ] image as a starting layer, adds some bits to inter-operate with AWS SageMaker (i.e., github.com/aws/sagemaker-containers), and copies in custom entypoint code that will run when the Estimator is spawned. We'll discuss the custom logic in the section below, for now lets actually build our container and push it to the Amazon Elastic Container Registry (ECR). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapids_base_container = 'rapidsai/rapidsai-nightly:0.15-cuda10.1-runtime-ubuntu18.04-py3.7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decide on the full name of our container `image_base:image_tag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base = 'cloud-ml-sagemaker'\n",
    "image_tag  = rapids_base_container.split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_fullname = f\"{account[0]}.dkr.ecr.{region[0]}.amazonaws.com/{image_base}:{image_tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 2.1.1 - Write Dockerfile </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write out the Dockerfile in this cell, write it to disk, and in the next cell execute the docker build command.\n",
    "> Note that we're copying in custom logic [ train.py, rapids_csp. py ] that we'll be defining shortly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir='~/SageMaker/cloud-ml-examples/aws/code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%cd {workdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "# make sure the container base matches {rapids_base_container}\n",
    "FROM rapidsai/rapidsai-nightly:0.15-cuda10.1-runtime-ubuntu18.04-py3.7 \n",
    "\n",
    "# install https://github.com/aws/sagemaker-training-toolkit\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends build-essential \\ \n",
    "    && source activate rapids && pip3 install sagemaker-training\n",
    "\n",
    "# path where sagemaker looks for our code\n",
    "ENV CLOUD_PATH=\"/opt/ml/code\"\n",
    "\n",
    "# copy our latest [local] code into the container \n",
    "COPY rapids_cloud_ml.py $CLOUD_PATH/rapids_cloud_ml.py\n",
    "COPY train.py $CLOUD_PATH/train.py\n",
    "\n",
    "# sagemaker entrypoint will be train.py\n",
    "ENV SAGEMAKER_PROGRAM train.py \n",
    "\n",
    "WORKDIR $CLOUD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate that our desired rapids image matches the Dockerfile\n",
    "with open('Dockerfile') as df: \n",
    "    assert( rapids_base_container in df.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 2.1.2 Build and Tag </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build usually take less than 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!docker build . -t $ecr_fullname -f Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 2.1.3 - Publish to Elastic Cloud Registry (ECR) </span>\n",
    "\n",
    "Now that we've built and tagged our container its time to push it to Amazon's container registry (ECR). Once in ECR, AWS SageMaker will be able to leverage our image to build Estimators and run experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Login to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_login_str = !(aws ecr get-login --region {region[0]} --no-include-email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{docker_login_str[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ECR repository [ if it doesn't already exist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_query = !(aws ecr describe-repositories --repository-names $image_base)\n",
    "if repository_query[0] == '':\n",
    "    !(aws ecr create-repository --repository-name $image_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now actually push the container to ECR\n",
    "> Note the first push to ECR may take some time (hopefully less than 10 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push $ecr_fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 2.2 - Create Estimator </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having built our container [ +custom logic] and pushed it to ECR, we can finally compile all of efforts into an **Estimator** object -- you can think of the Estimator as the software stack that AWS SageMaker will replicate to each worker node.\n",
    "\n",
    "We'll build the Estimator using our SageMaker execution role, the ECR image we built/tagged, and add an output path to [optionally] save models trained during the HPO experimentation.\n",
    "\n",
    "For additional options and details see the [Estimator documentation](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator) (e.g., to change the size in GB of the EBS volume to use for storing input data during training, default = 30GB )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_params = {\n",
    "    \n",
    "    'sagemaker_session' : sm_session,     \n",
    "    'role' : sm_execution_role,\n",
    "    \n",
    "    'image_name' : ecr_fullname,\n",
    "    \n",
    "    'train_instance_type' : instance_type, \n",
    "    'train_instance_count' : 1, \n",
    "    \n",
    "    'train_use_spot_instances': use_spot_instances_flag,\n",
    "    \n",
    "    'train_max_run' : max_duration_of_experiment_seconds,\n",
    "    'train_max_wait' : max_duration_of_experiment_seconds+1,     \n",
    "    \n",
    "    'input_mode' : 'File'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_estimator = sagemaker.estimator.Estimator( **estimator_params  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 2.3 - Test Estimator </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to test by asking SageMaker to run the BYOContainer logic inside our Estimator. This is a useful step if you've made changes to your custom logic and are interested in making sure everything works before launching a large HPO search. \n",
    "\n",
    "> Note: This verification step will use the default hyper-parameter values declared in our custom train code, as SageMaker HPO will not be orchestrating a search for this single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ( input('confirm test run? [ y / n ] : ').lower() == 'y' )\n",
    "\n",
    "job_name = new_job_name_from_config( dataset_directory, code_choice, \n",
    "                                     algorithm_choice, cv_folds,\n",
    "                                     instance_type  )\n",
    "\n",
    "sm_estimator.fit(inputs = s3_data_URI, job_name=job_name.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> 3 - HPO </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a working SageMaker Estimator in hand, the hardest part is behind us. Now all we have to do is tell SageMaker about the space of hyper-parameters in which to search for the best model.\n",
    "\n",
    "For more documentation check out the AWS SageMaker [HyperParameter Tuner documentation](https://sagemaker.readthedocs.io/en/stable/tuner.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.1 - Define Metric </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definitions below specify a regular expressions (i.e., string parsing rules) to find the metrics which we are using to evalaute performance in the output log of each worker/Estimator. In this case we are case we are onyl interested in the performance of our model on the test data (i.e., `test-accuracy`), so we have a single metric to track.\n",
    "\n",
    "For additional details on metrics refer to the [AWS SageMaker documentation on Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{'Name': 'test-accuracy', 'Regex': 'test-accuracy: (.*);'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'test-accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.2 - Define Tuner </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are setting up the parameters that will define the HPO job. By default (to avoid accidently spawning large compute jobs), we have limited the number of HPO experiments to run to 2.\n",
    "\n",
    "To run a more realistic large-scale HPO, change `max_jobs` to 100 and `max_parallel_jobs` to 10 (or as high as your instance limit permits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = sagemaker.tuner.HyperparameterTuner( estimator = sm_estimator,\n",
    "                                           metric_definitions = metric_definitions, \n",
    "                                           objective_metric_name = objective_metric_name,\n",
    "                                           objective_type = 'Maximize',\n",
    "                                           hyperparameter_ranges = hyperparameter_ranges,\n",
    "                                           strategy = search_strategy,  \n",
    "                                           max_jobs = max_jobs,\n",
    "                                           max_parallel_jobs = max_parallel_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.3 - Run HPO </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_choices( s3_data_URI, code_choice, algorithm_choice, cv_folds,\n",
    "                   instance_type, use_spot_instances_flag, search_strategy, \n",
    "                   max_jobs, max_parallel_jobs, max_duration_of_experiment_seconds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be sure we take a moment to confirm before launching all of our HPO experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ( input('confirm HPO launch? [ y / n ] : ').lower() == 'y' )\n",
    "\n",
    "tuning_job_name = new_job_name_from_config( dataset_directory, code_choice, \n",
    "                                            algorithm_choice, cv_folds, \n",
    "                                            instance_type )\n",
    "hpo.fit( inputs = s3_data_URI, \n",
    "         job_name = tuning_job_name, \n",
    "         wait = True, logs = 'All') \n",
    "\n",
    "hpo.wait() # block until the .fit call above is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/run_hpo.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.4 - Results and Summary </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name).dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS SageMaker + NVIDIA RAPIDS HPO FTW!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> Rapids References </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cloud-ml-examples](http://github.com/rapidsai/cloud-ml-examples)\n",
    "\n",
    "[cuML Documentation](https://docs.rapids.ai/api/cuml/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> SageMaker References </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit)\n",
    "\n",
    "[Estimator Parameters](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)\n",
    "\n",
    "Spot Instances [docs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html), and [blog]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year of data, NVIDIA V100 vs Intel Xeon-5.2698\n",
    "    > ingestion : speedup: 13.79 x  -- cpu: 22.70 seconds, gpu: 1.65 seconds\n",
    "    > dropna : speedup: 86.62 x  -- cpu: 5.52 seconds, gpu: 0.06 seconds\n",
    "    > split : speedup: 26.08 x  -- cpu: 2.66 seconds, gpu: 0.10 seconds\n",
    "    > RandomForest.train : speedup: 11.92 x  -- cpu: 16.73 seconds, gpu: 1.40 seconds\n",
    "    > RandomForest.predict : speedup: 14.27 x  -- cpu: 0.57 seconds, gpu: 0.04 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
